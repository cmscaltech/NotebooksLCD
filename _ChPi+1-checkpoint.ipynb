{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import h5py\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "#from keras.models import Sequential, Model, model_from_json\n",
    "#from keras.layers import Dense, Activation, Input, Dense, Dropout, merge, Reshape, Convolution3D, MaxPooling3D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#%matplotlib inline\n",
    "\n",
    "# Assume that you have 12GB of GPU memory and want to allocate ~4GB:\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "if __package__ is None:\n",
    "    sys.path.append(os.path.realpath(\"/home/vitoriabp/RegressionLCD/\"))\n",
    "    \n",
    "from model import *\n",
    "from preprocessing import *\n",
    "from plots import *\n",
    "\n",
    "if __package__ is None:\n",
    "    sys.path.append(os.path.realpath(\"/data/shared/Software/CMS_Deep_Learning\"))\n",
    "    \n",
    "from CMS_Deep_Learning.io import gen_from_data, retrieve_data\n",
    "from CMS_Deep_Learning.postprocessing.metrics import distribute_to_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def defModel(loss='mse', name=\"regression\"):\n",
    "    '''\n",
    "    Regression model that has ECAL and HCAL as inputs.\n",
    "    :parameter loss: Keras' loss function to be used. Recommended: mse, mean_absolute_error,\n",
    "     mean_squared_logarithmic_error, mean_absolute_percentage_error.\n",
    "    :type loss: str\n",
    "    :parameter name: name to save the file as.\n",
    "    :type name: str\n",
    "    :return: model.\n",
    "    '''\n",
    "\n",
    "    # ECAL input\n",
    "    input1 = Input(shape=(25, 25, 25))\n",
    "    r = Reshape((25, 25, 25, 1))(input1)\n",
    "    model1 = Convolution3D(3, 5, 5, 5, activation='relu')(r)\n",
    "    model1 = MaxPooling3D()(model1)\n",
    "    model1 = Flatten()(model1)\n",
    "\n",
    "    # HCAL input\n",
    "    input2 = Input(shape=(5, 5, 60))\n",
    "    r = Reshape((5, 5, 60, 1))(input2)\n",
    "    model2 = Convolution3D(10, 3, 3, 6, activation='relu')(r)\n",
    "    #model2 = Convolution3D(10, 2, 2, 6, activation='relu')(r)\n",
    "    model2 = MaxPooling3D()(model2)\n",
    "    model2 = Flatten()(model2)\n",
    "\n",
    "    # join the two input models\n",
    "    bmodel = merge([model1, model2], mode='concat')  # branched model\n",
    "\n",
    "    # fully connected ending\n",
    "    bmodel = (Dense(1000, activation='relu'))(bmodel)\n",
    "    bmodel = (Dropout(0.5))(bmodel)\n",
    "\n",
    "    # oc = Dense(1,activation='sigmoid', name='particle_label')(bmodel) # output particle classification\n",
    "    oe = Dense(1, activation='linear', name='energy')(bmodel)  # output energy regression\n",
    "\n",
    "    # classification, will not use yet\n",
    "    # bimodel = Model(input=[input1,input2], output=[oc,oe])\n",
    "    # bimodel.compile(loss=['binary_crossentropy', 'mse'], optimizer='sgd')\n",
    "    # bimodel.summary()\n",
    "\n",
    "    # energy regression model\n",
    "    model = Model(input=[input1, input2], output=oe)\n",
    "    model.compile(loss=loss, optimizer='adam')\n",
    "    model.summary()\n",
    "    saveModel(model, name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining model\n",
    "\n",
    "chPi = defModel(name=\"chPi+1\")\n",
    "\n",
    "chPi.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "saveModel(chPi, \"chPi+1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Generator\n",
    "# Defining the directories, which contain the splitted data\n",
    "\n",
    "train_dir = \"/bigdata/shared/LCD/V1/ChPiEscan/train\"\n",
    "valid_dir = \"/bigdata/shared/LCD/V1/ChPiEscan/valid\"\n",
    "test_dir = \"/bigdata/shared/LCD/V1/ChPiEscan/test\"\n",
    "\n",
    "# Danny's generator\n",
    "\n",
    "# training set:\n",
    "train = gen_from_data(train_dir, batch_size=500, data_keys=[[\"ECAL\", \"HCAL\"], \"target\"], prep_func=reshapeData)\n",
    "\n",
    "# validation set:\n",
    "val = gen_from_data(valid_dir, batch_size=500, data_keys=[[\"ECAL\", \"HCAL\"], \"target\"], prep_func=reshapeData)\n",
    "\n",
    "# testing set:\n",
    "test = gen_from_data(valid_dir, batch_size=500, data_keys=[[\"ECAL\", \"HCAL\"], \"target\"], prep_func=reshapeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Training\n",
    "\n",
    "tr_samples = nSamples(\"/bigdata/shared/LCD/V1/ChPiEscan/train/\")\n",
    "\n",
    "print tr_samples\n",
    "\n",
    "val_samples = nSamples(\"/bigdata/shared/LCD/V1/ChPiEscan/valid/\")\n",
    "\n",
    "print val_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = chPi.fit_generator(train, samples_per_epoch=tr_samples, \n",
    "                           nb_epoch=400,\n",
    "                           validation_data = val, \n",
    "                           nb_val_samples=val_samples, verbose=1,\n",
    "                           callbacks=ModelCheckpoint(filepath='/home/vitoriabp/CaloImage_2017/chPi.h5', verbose=0)\n",
    "                             )\n",
    "\n",
    "## Test\n",
    "testDir = '/bigdata/shared/LCD/V1/ChPiEscan/test' # test directory where you get the targets from\n",
    "mod = '/home/vitoriabp/CaloImage_2017/chPi.json' # model file\n",
    "w = '/home/vitoriabp/CaloImage_2017/chPi.h5' # weights file\n",
    "\n",
    "from CMS_Deep_Learning.io import simple_grab\n",
    "\n",
    "# grab y and predictions together\n",
    "all_y, all_pred, = simple_grab(['Y', 'predictions'], data = testDir, label_keys='target',\n",
    "                               input_keys=['ECAL', 'HCAL'], model = mod, weights = w)\n",
    "print all_pred.shape\n",
    "\n",
    "all_y = all_y[:, 1:]\n",
    "print(all_y.shape)\n",
    "\n",
    "print all_pred\n",
    "\n",
    "#print all_y\n",
    "\n",
    "#plotPredictedXTarget(all_y, all_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
